{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a808d0e",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Illusory Pitch Study"
   ]
  },
  {
   "cell_type": "code",
   "id": "7adbd600",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from glob import glob\n",
    "\n",
    "def dprime_and_c(hit_rate, fa_rate):\n",
    "    \n",
    "    # Get corresponding z-scores for the hit rate and false alarm rate\n",
    "    zH = stats.norm.ppf(hit_rate)\n",
    "    zF = stats.norm.ppf(fa_rate)\n",
    "    \n",
    "    # Calculate d' and C using z-scores\n",
    "    dprime = zH - zF\n",
    "    C = -(zH + zF) / 2\n",
    "    \n",
    "    return dprime, C"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6128fd80",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c327fc7",
   "metadata": {},
   "source": [
    "# Find all data files\n",
    "datafiles = glob('../data/IPAD_*.csv')\n",
    "\n",
    "# Load each data file and concatenate them into a single table\n",
    "d = pd.concat((pd.read_csv(f) for f in datafiles))\n",
    "\n",
    "# Select only main trial events\n",
    "d = d[d.event == 'trial']\n",
    "\n",
    "# Recode the pitch shift and key press as 0 for \"lower\" and 1 for \"higher\"\n",
    "d = d.assign(answer = d['shift'] == '+',\n",
    "            response = d['response'] == '+')\n",
    "\n",
    "# Before version 1.1, the experiment always loaded the stimuli for difficulty 1.0, so manually overwrite recorded trial difficulty\n",
    "d.loc[d.version < 1.1, 'difficulty'] = 1.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f53546f1",
   "metadata": {},
   "source": [
    "### Calculate scores within each subject and condition"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a39b743",
   "metadata": {},
   "source": [
    "# Define conditions as (octave, offset) pairs\n",
    "conditions = [(1, 425), (1, 500), (1, 575), (0.5, 425), (0.5, 500), (0.5, 575)]\n",
    "shift_sizes = [1, 0.5]\n",
    "intervals = [425, 500, 575]\n",
    "offsets = [-15, 0, 15]\n",
    "\n",
    "# Scores will be stored in a long-format table\n",
    "scores = pd.DataFrame(columns=['subject', 'experimenter', 'version', 'jnd', 'shift_size', 'interval', 'offset',\n",
    "                               'hit_rate', 'fa_rate', 'accuracy', 'perc_resp_low', 'dprime', 'C', 'rt'])\n",
    "fits = pd.DataFrame(columns=['subject', 'experimenter', 'version', 'jnd', 'shift_size', 'C_intercept', 'C_slope'])\n",
    "\n",
    "# Calculate scores for each subject\n",
    "for s, subj in enumerate(d.subject.unique()):\n",
    "\n",
    "    # Select all responses from the current subject\n",
    "    subj_trials = d[d.subject == subj]\n",
    "    experimenter = subj_trials.iloc[-1].experimenter\n",
    "    exp_version = subj_trials.iloc[-1].version\n",
    "    jnd = subj_trials.iloc[-1].jnd\n",
    "    \n",
    "    # Calculate scores within each condition\n",
    "    C_values = np.full((len(intervals), len(shift_sizes)+1), np.nan)\n",
    "    for i, interval in enumerate(intervals):\n",
    "        \n",
    "        interval_trials = subj_trials[subj_trials.interval == interval]\n",
    "        \n",
    "        # Calculate hit and false alarm rates, pooling across difficulties, using Hautus (1995) adjustment to avoid 0s and 1s\n",
    "        hit_rate = (np.sum(interval_trials.answer & interval_trials.response) + .5) / (np.sum(interval_trials.answer) + 1)\n",
    "        fa_rate = (np.sum(~interval_trials.answer & interval_trials.response) + .5) / (np.sum(~interval_trials.answer) + 1)\n",
    "\n",
    "        # Calculate C based on the hit rate and false alarm rate\n",
    "        _, C = dprime_and_c(hit_rate, fa_rate)\n",
    "        C_values[i, -1] = C\n",
    "        \n",
    "        # Calculate scores for each probe timing offset and pitch shift size\n",
    "        for j, shift_size in enumerate(shift_sizes):\n",
    "            \n",
    "            # Select all trials from the current condition\n",
    "            trials = interval_trials[interval_trials.difficulty == shift_size]\n",
    "            if len(trials) == 0:\n",
    "                continue\n",
    "\n",
    "            # Create dictionary to store scores from current subject and condition\n",
    "            offset = offsets[i]\n",
    "            condi_scores = dict(subject=subj, experimenter=experimenter, version=exp_version, shift_size=shift_size, interval=interval, offset=offset)\n",
    "        \n",
    "            # Calculate accuracy and the percent of the time the participant responded \"lower\"\n",
    "            condi_scores['accuracy'] = np.mean(trials.correct)\n",
    "            condi_scores['perc_resp_low'] = np.mean(~trials.response)\n",
    "            \n",
    "            # Calculate hit and false alarm rates using Hautus (1995) adjustment to avoid 0s and 1s\n",
    "            condi_scores['hit_rate'] = (np.sum(trials.answer & trials.response) + .5) / (np.sum(trials.answer) + 1)\n",
    "            condi_scores['fa_rate'] = (np.sum(~trials.answer & trials.response) + .5) / (np.sum(~trials.answer) + 1)\n",
    "        \n",
    "            # Calculate d' and C based on the hit rate and false alarm rate\n",
    "            condi_scores['dprime'], condi_scores['C'] = dprime_and_c(condi_scores['hit_rate'], condi_scores['fa_rate'])\n",
    "            C_values[i, j] = condi_scores['C']\n",
    "    \n",
    "            condi_scores['rt'] = trials.rt.mean()\n",
    "            condi_scores['jnd'] = jnd\n",
    "        \n",
    "            # Add current scores as a row to the full table of scores\n",
    "            scores.loc[len(scores.index)] = condi_scores\n",
    "    \n",
    "    # Calculate timing-induced bias by fitting a line across the three C values for different offsets, separately for each shift size\n",
    "    for i in range(len(shift_sizes) + 1):\n",
    "        \n",
    "        # Skip current shift size if participant did not receive this difficulty\n",
    "        if np.all(np.isnan(C_values[:, i])):\n",
    "            continue\n",
    "        \n",
    "        shift_size = shift_sizes[i] if i < len(shift_sizes) else 'pooled'\n",
    "        fit_data = dict(subject=subj, experimenter=experimenter, version=exp_version, shift_size=shift_size, jnd=jnd)\n",
    "        \n",
    "        # Fit a line across the three C values at the current shift size\n",
    "        slope, intercept = np.polyfit(offsets, C_values[:, i], 1)\n",
    "    \n",
    "        # Add the slope and intercept of the line to the subject's data dictionary\n",
    "        fit_data['C_intercept'] = intercept\n",
    "        fit_data['C_slope'] = slope\n",
    "        \n",
    "        # Add subject's data to the overall dataframe\n",
    "        fits.loc[len(fits.index)] = fit_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scores.to_csv('../data/scores.csv', index=False)\n",
    "fits.to_csv('../data/fits.csv', index=False)"
   ],
   "id": "26d215caa57b45b3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
