{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a808d0e",
   "metadata": {},
   "source": [
    "# Data Processing: Illusory Pitch"
   ]
  },
  {
   "cell_type": "code",
   "id": "7adbd600",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from glob import glob\n",
    "\n",
    "def dprime_and_c(hit_rate, fa_rate):\n",
    "    \n",
    "    # Get corresponding z-scores for the hit rate and false alarm rate\n",
    "    zH = stats.norm.ppf(hit_rate)\n",
    "    zF = stats.norm.ppf(fa_rate)\n",
    "    \n",
    "    # Calculate d' and C using z-scores\n",
    "    dprime = zH - zF\n",
    "    C = -(zH + zF) / 2\n",
    "    \n",
    "    return dprime, C"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6128fd80",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c327fc7",
   "metadata": {},
   "source": [
    "# Find all data files\n",
    "datafiles = glob('../data/Il*.csv')\n",
    "\n",
    "# Load each data file and concatenate them into a single table\n",
    "d = pd.concat((pd.read_csv(f) for f in datafiles))\n",
    "\n",
    "# Select only non-pilot participants\n",
    "d = d[d.code_version == 'v1.0']\n",
    "\n",
    "# Select only trial response events\n",
    "d = d[d.event == 'response']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mark responses as correct or incorrect and save trial data",
   "id": "e0a5f7045352c969"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Recode the pitch shift and key press as 0 for \"lower\" and 1 for \"higher\"\n",
    "d = d.assign(answer = d.pitch_shift == '+',\n",
    "             response = d.key_press.astype(int) == 38)\n",
    "\n",
    "# Mark whether each response was correct by comparing it to the correct answer\n",
    "d = d.assign(correct = d.answer == d.response)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "d = d.drop(columns=['trial_type', 'trial_index', 'internal_node_id', 'stimulus', 'event', 'key_press'])\n",
    "\n",
    "# Save trial data\n",
    "d.to_csv('../data/response_data.csv', index=False)"
   ],
   "id": "e678ccaff640f93e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f53546f1",
   "metadata": {},
   "source": [
    "### Calculate scores within each subject and condition"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a39b743",
   "metadata": {},
   "source": [
    "# Define conditions as (octave, offset) pairs\n",
    "conditions = [(3, -15), (3, 0), (3, 15), (5, -15), (5, 0), (5, 15)]\n",
    "\n",
    "# Scores will be stored in a long-format table\n",
    "scores = pd.DataFrame(columns=['subject', 'octave', 'offset',\n",
    "                               'hit_rate', 'fa_rate', 'accuracy', \n",
    "                               'perc_resp_low', 'dprime', 'C'])\n",
    "\n",
    "# Calculate scores for each subject\n",
    "for s, subj in enumerate(d.subject.unique()):\n",
    "    \n",
    "    # Select all responses from the current subject\n",
    "    subj_trials = d[d.subject == subj]\n",
    "    \n",
    "    # Calculate scores within each condition\n",
    "    for i, condition in enumerate(conditions):\n",
    "        \n",
    "        # Select all trials from the current condition\n",
    "        octave = condition[0]\n",
    "        offset = condition[1]\n",
    "        trials = subj_trials[(subj_trials.octave == octave) & (subj_trials.offset == offset)]\n",
    "        \n",
    "        # Create dictionary to store scores from current subject and condition\n",
    "        condi_scores = {'subject': subj, 'octave': octave, 'offset': offset}\n",
    "        \n",
    "        # Calculate accuracy and the percent of the time the participant responded \"lower\"\n",
    "        condi_scores['accuracy'] = np.mean(trials.correct)\n",
    "        condi_scores['perc_resp_low'] = np.mean(~trials.response)\n",
    "        \n",
    "        # Calculate hit and false alarm rates using Hautus (1995) adjustment to avoid 0s and 1s\n",
    "        condi_scores['hit_rate'] = (np.sum(trials.answer & trials.response) + .5) / (np.sum(trials.answer) + 1)\n",
    "        condi_scores['fa_rate'] = (np.sum(~trials.answer & trials.response) + .5) / (np.sum(~trials.answer) + 1)\n",
    "        \n",
    "        # Calculate d' and C based on the hit rate and false alarm rate\n",
    "        condi_scores['dprime'], condi_scores['C'] = dprime_and_c(condi_scores['hit_rate'], condi_scores['fa_rate'])\n",
    "        \n",
    "        # Add current scores as a row to the full table of scores\n",
    "        scores.loc[len(scores.index)] = condi_scores"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d7c90aa2",
   "metadata": {},
   "source": [
    "### Save processed scores to a file"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef70698b",
   "metadata": {},
   "source": "scores.to_csv('../data/scores.csv', index=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6556166253ed15d0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
